{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#My section"
      ],
      "metadata": {
        "id": "vW6rltPbEDG3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "from utils import download_images\n",
        "train = pd.read_csv('/content/dataset/train.csv')\n",
        "test = pd.read_csv('/content/dataset/test.csv')"
      ],
      "metadata": {
        "id": "6WCduVkGEXQM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib.parse\n",
        "temp_train = train.head(500) #changing number of rows to train with\n",
        "download_images(temp_train['image_link'],'train_images')\n",
        "df = temp_train\n",
        "for i,row in df.iterrows():\n",
        "  image_link = row['image_link']\n",
        "  parsed_url = urllib.parse.urlparse(image_link)\n",
        "  filename = os.path.basename(parsed_url.path)\n",
        "  new_filename = f\"{i}.jpg\"\n",
        "  if os.path.exists(filename):\n",
        "    os.rename(filename,new_filename)"
      ],
      "metadata": {
        "id": "lNDd9MWNFfc-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7fd9477-5534-46a2-e90a-d3e7d74fb89e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 500/500 [00:02<00:00, 203.42it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "\n",
        "def preprocess_image(image_path, target_size=(224, 224)):\n",
        "    img = cv2.imread(image_path)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    img = cv2.resize(img, target_size)\n",
        "    img = img.astype(np.float32) / 255.0\n",
        "    return img\n",
        "\n",
        "def preprocess_dataset(image_dir, output_dir, target_size=(224, 224)):\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    for filename in tqdm(os.listdir(image_dir)):\n",
        "        if filename.endswith(('.jpg', '.jpeg', '.png')):\n",
        "            input_path = os.path.join(image_dir, filename)\n",
        "            output_path = os.path.join(output_dir, filename)\n",
        "            preprocessed_img = preprocess_image(input_path, target_size)\n",
        "            cv2.imwrite(output_path, cv2.cvtColor((preprocessed_img * 255).astype(np.uint8), cv2.COLOR_RGB2BGR))\n",
        "\n",
        "# Preprocess training and test datasets\n",
        "preprocess_dataset('train_images', 'preprocessed_images1')\n",
        "\n",
        "print(\"Image preprocessing complete!\")"
      ],
      "metadata": {
        "id": "anFQbYALGU1E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "from constants import entity_unit_map  # Import the entity-to-unit mapping\n",
        "\n",
        "def preprocess_labels(df):\n",
        "    def extract_value_and_unit(entity_value):\n",
        "        match = re.match(r'(\\d+(?:\\.\\d+)?)\\s*(\\w+)', str(entity_value))\n",
        "        if match:\n",
        "            value, unit = match.groups()\n",
        "            return float(value), unit.lower()\n",
        "        return None, None\n",
        "\n",
        "    def normalize_unit(unit, entity_name):\n",
        "        # Fetch the allowed units for the given entity\n",
        "        allowed_units_for_entity = entity_unit_map.get(entity_name, set())\n",
        "        if unit in allowed_units_for_entity:\n",
        "            return unit\n",
        "        # You can add unit conversion logic here if needed\n",
        "        return None\n",
        "\n",
        "    # Extract value and unit\n",
        "    df['value'], df['unit'] = zip(*df['entity_value'].map(extract_value_and_unit))\n",
        "\n",
        "    # Normalize units based on entity names\n",
        "    df['normalized_unit'] = df.apply(lambda row: normalize_unit(row['unit'], row['entity_name']), axis=1)\n",
        "\n",
        "    # Remove rows with invalid units\n",
        "    # df = df.dropna(subset=['normalized_unit'])\n",
        "\n",
        "    return df\n",
        "\n",
        "# Load the training data\n",
        "train_df = temp_train\n",
        "# train_df = pd.read_csv('dataset/train.csv')\n",
        "\n",
        "# Preprocess the labels\n",
        "preprocessed_train_df = preprocess_labels(train_df)\n",
        "print(preprocessed_train_df.shape)\n",
        "# Save the preprocessed data\n",
        "preprocessed_train_df.to_csv('train_labels.csv', index=False)\n",
        "\n",
        "print(\"Label preprocessing complete!\")"
      ],
      "metadata": {
        "id": "SxX60sO1JRhs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "model dev"
      ],
      "metadata": {
        "id": "qCeZfoY1HQhL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get update\n",
        "!apt-get install -y tesseract-ocr\n",
        "!pip install pytesseract"
      ],
      "metadata": {
        "id": "NaNevUynJSm8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import pytesseract\n",
        "import pandas as pd\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "\n",
        "def perform_ocr(image_path):\n",
        "    img = cv2.imread(image_path)\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    threshold = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)[1]\n",
        "    text = pytesseract.image_to_string(threshold)\n",
        "    return text\n",
        "\n",
        "def extract_ocr_features(image_dir, limit=10000):\n",
        "    ocr_features = {}\n",
        "    image_files = [filename for filename in os.listdir(image_dir) if filename.endswith(('.jpg', '.jpeg', '.png'))]\n",
        "\n",
        "    for i, filename in enumerate(tqdm(image_files)):\n",
        "        if i >= limit:\n",
        "            break\n",
        "        image_path = os.path.join(image_dir, filename)\n",
        "        image_id = os.path.splitext(filename)[0]\n",
        "        ocr_text = perform_ocr(image_path)\n",
        "        ocr_features[image_id] = ocr_text\n",
        "\n",
        "    return ocr_features\n",
        "\n",
        "# Extract OCR features for training and test sets, limiting to 10,000 images\n",
        "train_ocr_features = extract_ocr_features('preprocessed_images1', limit=10000)\n",
        "# test_ocr_features = extract_ocr_features('preprocessed_images2', limit=10000)\n",
        "\n",
        "# Save OCR features\n",
        "pd.DataFrame.from_dict(train_ocr_features, orient='index', columns=['ocr_text']).to_csv('train_ocr_features.csv')\n",
        "# pd.DataFrame.from_dict(test_ocr_features, orient='index', columns=['ocr_text']).to_csv('test_ocr_features.csv')\n",
        "\n",
        "print(\"OCR feature extraction complete!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y7JPtKdzHadQ",
        "outputId": "e9a880d4-aef5-469d-eb5e-4cd7046bb5ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 494/494 [02:13<00:00,  3.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OCR feature extraction complete!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision import models, transforms\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "\n",
        "model=models.resnet50(pretrained=True)\n",
        "model = torch.nn.Sequential(*list(model.children())[:-1])\n",
        "model.eval()\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485,0.456,0.406],std=[0.229,0.224,0.225]),\n",
        "])\n",
        "\n",
        "def extract_cnn_features(image_path):\n",
        "  img = Image.open(image_path).convert('RGB')\n",
        "  img_tensor = transform(img).unsqueeze(0)\n",
        "  with torch.no_grad():\n",
        "    features = model(img_tensor)\n",
        "  return features.squeeze().numpy()\n",
        "\n",
        "def extract_cnn_features_batch(image_dir):\n",
        "  cnn_features = {}\n",
        "  for filename in tqdm(os.listdir(image_dir)):\n",
        "    if filename.endswith(('.jpg','.jpeg','.png')):\n",
        "      image_path = os.path.join(image_dir,filename)\n",
        "      image_id = os.path.splitext(filename)[0]\n",
        "      features = extract_cnn_features(image_path)\n",
        "      cnn_features[image_id] = features\n",
        "  return cnn_features\n",
        "\n",
        "train_cnn_features = extract_cnn_features_batch('preprocessed_images1')\n",
        "\n",
        "pd.DataFrame.from_dict(train_cnn_features,orient='index').to_csv('train_cnn_features.csv')\n",
        "\n",
        "print('cnn extraction coplete')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4NXlXJ9w_MDB",
        "outputId": "7a8363a3-ef69-402d-c0a2-e5e21fee8abc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
            "100%|██████████| 97.8M/97.8M [00:00<00:00, 126MB/s]\n",
            "100%|██████████| 494/494 [01:55<00:00,  4.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cnn extraction coplete\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "metadata": {
        "id": "3zl5oxFXHbSH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ProductDataset(Dataset):\n",
        "    def __init__(self, ocr_features, cnn_features, labels):\n",
        "        self.ocr_features = torch.tensor(ocr_features, dtype=torch.long)  # Convert to tensor\n",
        "        self.cnn_features = torch.tensor(cnn_features, dtype=torch.float)  # Convert to tensor\n",
        "        self.labels = torch.tensor(labels, dtype=torch.long)  # Convert to tensor\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {\n",
        "            'ocr': self.ocr_features[idx],\n",
        "            'cnn': self.cnn_features[idx],\n",
        "            'label': self.labels[idx]\n",
        "        }\n"
      ],
      "metadata": {
        "id": "c11uL00bHfLr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class HybridModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, cnn_feature_dim, num_classes):\n",
        "        super(HybridModel, self).__init__()\n",
        "\n",
        "        # OCR branch\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
        "\n",
        "        # CNN branch\n",
        "        self.fc_cnn = nn.Linear(cnn_feature_dim, hidden_dim)\n",
        "\n",
        "        # Combined layers\n",
        "        self.fc_combined = nn.Sequential(\n",
        "            nn.Linear(hidden_dim * 2, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, num_classes)\n",
        "        )\n",
        "    def forward(self, ocr, cnn):\n",
        "        # OCR branch\n",
        "        ocr_emb = self.embedding(ocr)\n",
        "        ocr_out, _ = self.lstm(ocr_emb)\n",
        "        ocr_out = ocr_out[:, -1, :]  # Take the last output\n",
        "\n",
        "        # CNN branch\n",
        "        cnn_out = self.fc_cnn(cnn)\n",
        "\n",
        "        # Combine and predict\n",
        "        combined = torch.cat((ocr_out, cnn_out), dim=1)\n",
        "        output = self.fc_combined(combined)\n",
        "\n",
        "        return output"
      ],
      "metadata": {
        "id": "bu6cE8R6HjwG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def safe_read_csv(file_path, index_col=None):\n",
        "    \"\"\"\n",
        "    Safely read a CSV file with error handling for non-existent or empty files.\n",
        "\n",
        "    Args:\n",
        "    - file_path (str): Path to the CSV file.\n",
        "    - index_col (int or str, optional): Column to set as index. Defaults to None.\n",
        "\n",
        "    Returns:\n",
        "    - pd.DataFrame: DataFrame containing the CSV data.\n",
        "    \"\"\"\n",
        "    if not os.path.exists(file_path):\n",
        "        raise FileNotFoundError(f\"File {file_path} does not exist.\")\n",
        "    if os.stat(file_path).st_size == 0:\n",
        "        raise ValueError(f\"File {file_path} is empty.\")\n",
        "    return pd.read_csv(file_path, index_col=index_col)\n",
        "\n",
        "# File paths\n",
        "ocr_features_path = 'train_ocr_features.csv'\n",
        "cnn_features_path = 'train_cnn_features.csv'\n",
        "labels_path = 'train_labels.csv'\n",
        "\n",
        "# Load features and labels\n",
        "try:\n",
        "    train_ocr = safe_read_csv(ocr_features_path, index_col=0)\n",
        "    train_cnn = safe_read_csv(cnn_features_path, index_col=0)\n",
        "    train_labels = safe_read_csv(labels_path)\n",
        "    print(\"Files loaded successfully!\")\n",
        "except FileNotFoundError as e:\n",
        "    print(f\"Error: {e}\")\n",
        "except ValueError as e:\n",
        "    print(f\"Error: {e}\")\n",
        "except pd.errors.EmptyDataError:\n",
        "    print(\"One or more files are empty.\")\n",
        "except Exception as e:\n",
        "    print(f\"An unexpected error occurred: {e}\")\n",
        "\n",
        "train_ocr.shape\n",
        "train_labels.shape\n",
        "# train_cnn.shape"
      ],
      "metadata": {
        "id": "16inEE65HqIZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59a42886-dc67-4f70-ff5d-c605f305f208"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files loaded successfully!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(480, 7)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def safe_read_csv(file_path, index_col=None):\n",
        "    \"\"\"\n",
        "    Safely read a CSV file with error handling for non-existent or empty files.\n",
        "\n",
        "    Args:\n",
        "    - file_path (str): Path to the CSV file.\n",
        "    - index_col (int or str, optional): Column to set as index. Defaults to None.\n",
        "\n",
        "    Returns:\n",
        "    - pd.DataFrame: DataFrame containing the CSV data.\n",
        "    \"\"\"\n",
        "    if not os.path.exists(file_path):\n",
        "        raise FileNotFoundError(f\"File {file_path} does not exist.\")\n",
        "    if os.stat(file_path).st_size == 0:\n",
        "        raise ValueError(f\"File {file_path} is empty.\")\n",
        "    return pd.read_csv(file_path, index_col=index_col)\n",
        "\n",
        "# File paths\n",
        "ocr_features_path = 'train_ocr_features.csv'\n",
        "cnn_features_path = 'train_cnn_features.csv'\n",
        "labels_path = 'train_labels.csv'\n",
        "\n",
        "# Load features and labels\n",
        "try:\n",
        "    train_ocr = safe_read_csv(ocr_features_path, index_col=0)\n",
        "    train_cnn = safe_read_csv(cnn_features_path, index_col=0)\n",
        "    train_labels = safe_read_csv(labels_path)\n",
        "    print(\"Files loaded successfully!\")\n",
        "except FileNotFoundError as e:\n",
        "    print(f\"Error: {e}\")\n",
        "except ValueError as e:\n",
        "    print(f\"Error: {e}\")\n",
        "except pd.errors.EmptyDataError:\n",
        "    print(\"One or more files are empty.\")\n",
        "except Exception as e:\n",
        "    print(f\"An unexpected error occurred: {e}\")\n",
        "\n",
        "le = LabelEncoder()\n",
        "train_labels['encoded_value'] = le.fit_transform(train_labels['value'])\n",
        "#split data\n",
        "train_data,val_data,train_labels,val_labels = train_test_split(\n",
        "    pd.concat([train_ocr,train_cnn],axis=1),\n",
        "    train_labels['encoded_value'],\n",
        "    test_size = 0.2,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "train_dataset = ProductDataset(train_data['ocr_text'].values,train_data.drop('ocr_text',axis=1).values,train_labels.values)\n",
        "val_dataset = ProductDataset(val_data['ocr_text'].values,val_data.drop('ocr_text',axis=1).values,val_labels.values)\n",
        "train_loader = DataLoader(train_dataset,batch_size=32,shuffle=True)\n",
        "val_loader = DataLoader(val_dataset,batch_size=32)\n",
        "\n",
        "#initialise model\n",
        "vocab_size = 10000\n",
        "embedding_dim = 100\n",
        "hidden_dim = 128\n",
        "cnn_features_diim = train_cnn.shape[1]\n",
        "num_classes = len(le.classes_)\n",
        "\n",
        "model = HybridModel(vocab_size, embedding_dim, hidden_dim, cnn_features_dim,num_classes)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "  model.train()\n",
        "  for batch in train_loader:\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(batch['ocr'],batch['cnn'])\n",
        "    loss = criterion(outputs,batch['label'])\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "  model.eval()\n",
        "  val_loss = 0\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  with torch.no_grad():\n",
        "    for batch in val_loader:\n",
        "      outputs = model(batch['ocr'],batch['cnn'])\n",
        "      loss = criterion(outputs, batch['label'])\n",
        "      val_loss += loss.item()\n",
        "      _,predicted = outputs.max(1)\n",
        "      total += batch['label'].size(0)\n",
        "      correct += predicted.eq(batch['label']).sum().item()\n",
        "print(f'Epoch {epoch+1}/{num_epochs}, '\n",
        "          f'Train Loss: {loss.item():.4f}, '\n",
        "          f'Val Loss: {val_loss/len(val_loader):.4f}, '\n",
        "          f'Val Accuracy: {100.*correct/total:.2f}%')\n",
        "\n",
        "torch.save(model.state_dict(),'model.pth')\n",
        "print('model training complete and saved')"
      ],
      "metadata": {
        "id": "i5WNHJRHHvBx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
